?reshape
my_data = data.frame(
x = eval_points,
y = y,
ll_10 = est_lower,
ul_10 = est_upper
)
my_data $ll_1 = my_data$y - (my_data$ul_10 - y) / 10
my_data $ul_1 = my_data$y + (my_data$ul_10 - y) / 10
my_data $ll_2 = my_data$y - (my_data$ul_10 - y) / 10 * 2
my_data $ul_2 = my_data$y + (my_data$ul_10 - y) / 10 * 2
my_data $ll_3 = my_data$y - (my_data$ul_10 - y) / 10 * 3
my_data $ul_3 = my_data$y + (my_data$ul_10 - y) / 10 * 3
my_data $ll_4 = my_data$y - (my_data$ul_10 - y) / 10 * 4
my_data $ul_4 = my_data$y + (my_data$ul_10 - y) / 10 * 4
my_data $ll_5 = my_data$y - (my_data$ul_10 - y) / 10 * 5
my_data $ul_5 = my_data$y + (my_data$ul_10 - y) / 10 * 5
my_data $ll_6 = my_data$y - (my_data$ul_10 - y) / 10 * 6
my_data $ul_6 = my_data$y + (my_data$ul_10 - y) / 10 * 6
my_data $ll_7 = my_data$y - (my_data$ul_10 - y) / 10 * 7
my_data $ul_7 = my_data$y + (my_data$ul_10 - y) / 10 * 7
my_data $ll_8 = my_data$y - (my_data$ul_10 - y) / 10 * 8
my_data $ul_8 = my_data$y + (my_data$ul_10 - y) / 10 * 8
my_data $ll_9 = my_data$y - (my_data$ul_10 - y) / 10 * 9
my_data $ul_9 = my_data$y + (my_data$ul_10 - y) / 10 * 9
my_data
head(my_data)
reshape(my_data, direction = "long", varying = list(ll_10:ul_9))
reshape(my_data, direction = "long", varying = list(3:22))
#' Density with Confidence Envelope
#'
#' This function creates a normal theory based confidence envelope for the empirical density.
#' Transparency is used to indicate the level of uncertainty.
#'
#' @inheritParams ggplot2::stat_identity
#' @param h A normal kernel function is used and `h` is its standard deviation. If this parameter is
#'     omitted, a normal optimal smoothing parameter is used.
#' @param fill Fill color for the confidence envelope. The default is `color="skyblue"`
#' @param fade Should the confidence enevelope have more transparency for values farther from the
#'      empirical density? The default is `fade=FALSE`.
#' @param model The model to bootstrap from. The default is `model="none"` which bootstraps from the data.
#'     Using `model="normal"` draws repeated samples from a normal distribution with parameters based on the
#'     ML estimates from the data.
#'
#' @importFrom dplyr %>%
#'
#' @export
StatDensityConfidence <- ggplot2::ggproto("StatDensityConfidence", ggplot2::Stat,
# Required aesthetics
required_aes = c("x"),
default_aes = ggplot2::aes(ymin = stat(lower_limit), ymax = stat(upper_limit), group = stat(group)),
# Computations
compute_group = function(data, scales, h = NULL, na.rm = TRUE,
fill = "skyblue", fade = FALSE,
model = "none", ...) {
if (length(unique(data$x)) < 2) {
# Not enough data to perform fit
return(new_data_frame())
}
# Compute smoothing parameter
if(is.null(h)){
h = (4 / (3*length(data$x))) ^ (1/5) * sd(data$x)
}
# Compute points at which to evaluate density
#eval_range = c(min(data$x) - diff(range(data$x)) / 4, max(data$x) + diff(range(data$x)) / 4)
eval_range = c(min(data$x), max(data$x))
eval_points = seq(from = eval_range[1], to = eval_range[2], length.out = 100)
# Compute SD for kernel
SD = sqrt(h^2 + var(data$x))
if(model == "normal") {
y = dnorm(eval_points, mean(data$x), SD)
} else{
y = density(data$x, bw = h, n = 100, from = eval_range[1], to = eval_range[2])$y
}
# Compute confidence limits
se <- sqrt(dnorm(0, sd = sqrt(2)*h) / (4 * length(data$x) * h))
upper <- sqrt(y) + 2 * se
lower <- pmax(sqrt(y) - 2 * se, 0)
upper <- upper^2
lower <- lower^2
est_se <- rep(se, length(eval_points))
est_upper <- upper
est_lower <- lower
# Output data for plotting
my_data = data.frame(
x = eval_points,
y = y,
lower_limit = est_lower,
upper_limit = est_upper,
group = 1,
alpha = 0.5
)
# if(fade) {
#
#   my_data = data.frame(
#     x = eval_points,
#     y = y,
#     ll_10 = est_lower,
#     ul_10 = est_upper
#   ) %>%
#     mutate(
#       ll_1 = y - (ul_10 - y) / 10,
#       ul_1 = y + (ul_10 - y) / 10,
#       ll_2 = y - (ul_10 - y) / 10 * 2,
#       ul_2 = y + (ul_10 - y) / 10 * 2,
#       ll_3 = y - (ul_10 - y) / 10 * 3,
#       ul_3 = y + (ul_10 - y) / 10 * 3,
#       ll_4 = y - (ul_10 - y) / 10 * 4,
#       ul_4 = y + (ul_10 - y) / 10 * 4,
#       ll_5 = y - (ul_10 - y) / 10 * 5,
#       ul_5 = y + (ul_10 - y) / 10 * 5,
#       ll_6 = y - (ul_10 - y) / 10 * 6,
#       ul_6 = y + (ul_10 - y) / 10 * 6,
#       ll_7 = y - (ul_10 - y) / 10 * 7,
#       ul_7 = y + (ul_10 - y) / 10 * 7,
#       ll_8 = y - (ul_10 - y) / 10 * 8,
#       ul_8 = y + (ul_10 - y) / 10 * 8,
#       ll_9 = y - (ul_10 - y) / 10 * 9,
#       ul_9 = y + (ul_10 - y) / 10 * 9
#     ) %>%
#     tidyr::pivot_longer(
#       cols = ll_10:ul_9,
#       names_to = c(".value", "group"),
#       names_sep = "_"
#     ) %>%
#     rename(lower_limit = ll, upper_limit = ul)
#
#   my_alpha = seq(from = 0.5, to = 0.1, length.out = 10)
#   my_data$alpha = I(my_alpha[as.numeric(my_data$group)])
# } else{
#
#   # Output data for plotting
#   my_data = data.frame(
#     x = eval_points,
#     y = y,
#     lower_limit = est_lower,
#     upper_limit = est_upper,
#     group = 1,
#     alpha = 0.5
#   )
#
# }
my_data
}
)
#' Stat Method for Density with Confidence Envelope
#'
#' This function creates a confidence enevelope for the empirical density. The idea came from
#' functions written by Bowman and Azzalini.
#'
#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @inheritParams StatDensityConfidence
#'
#' @section Aesthetics:
#' These stat uses  `geom_ribbon()` so support the
#' same aesthetics: `alpha`, `colour`, `linetype` and
#' `size`.
#'
#' @importFrom dplyr %>%
#' @export
stat_density_confidence <- function(mapping = NULL, data = NULL, geom = "ribbon",
position = "identity", na.rm = TRUE,
inherit.aes = TRUE, h = NULL, fill = "skyblue",
fade = FALSE, model = "none", ...) {
ggplot2::layer(
stat = StatDensityConfidence,
data = data,
mapping = mapping,
geom = geom,
position = position,
inherit.aes = inherit.aes,
params = list(
na.rm = na.rm,
h = h,
fill = fill,
model = model,
fade = fade,
#alpha = alpha,
...)
)
}
benchplot(ggplot(data =cars, aes(x = speed)) + stat_density_confidence())
benchplot(ggplot(data =cars, aes(x = speed)) + stat_density_confidence(model="normal"))
library(educate)
ggplot(data =cars, aes(x = speed)) + stat_density_confidence(model="normal", color = "red")
ggplot(data =cars, aes(x = speed)) + stat_density_confidence(model="normal", fill = "red")
library(educate)
library(educate)
ggplot(data =cars, aes(x = speed, y=dist)) + stat_density_confidence(model="normal", fill = "red")
ggplot(data =cars, aes(x = speed, y=dist)) + stat_density_confidence()
ggplot(data =cars, aes(x = speed, y=dist)) + stat_watercolor_density()
ggplot(data =cars, aes(x = speed, y=dist)) + stat_watercolor_density(model = "normal")
library(educate)
ggplot(data =cars, aes(x = speed, y=dist)) + stat_density_watercolor(model = "normal")
ggplot(data =cars, aes(x = speed)) + stat_density_watercolor(model = "normal")
library(educate)
library(educate)
ggplot(data =cars, aes(x = speed)) + stat_density_watercolor(model = "normal")
remotes::install_github("zief0002/educate")
knitr::opts_chunk$set(echo = TRUE)
# Load libraries
library(ggplot2)
library(scales)
library(educate)
ggplot(data = education, aes(x = salary)) +
stat_density_confidence() +
stat_density(geom = "line") +
theme_bw() +
scale_x_continuous(name = "Average teacher salary", labels = dollar) +
ylab("Probability density")
ggplot(data = education, aes(x = salary)) +
stat_density_confidence() +
stat_density(aes(y = ..density..), geom = "line", size = 0.5) +
theme_bw() +
scale_x_continuous(name = "Average teacher salary", labels = dollar) +
ylab("Probability density")
ggplot(data = cars, aes(x = speed)) +
stat_density_confidence() +
stat_density(geom = "line") +
theme_bw()
# Normal theory based confidence envelope from a normal distribution
ggplot(data = cars, aes(x = speed)) +
stat_density_confidence(model = "normal", fill = "red") +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Normal theory based confidence envelope from a normal distribution
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 100) +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Bootstrap based confidence envelope
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 100, alpha = 0.5) +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Bootstrap based confidence envelope
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 100, alpha = 0.4) +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Bootstrap based confidence envelope
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 100, alpha = 0.3) +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Bootstrap based confidence envelope
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 100, alpha = 0.1) +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Bootstrap based confidence envelope based on a normal distribution
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 100, alpha = 0.08, color = "orange", model = "normal") +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Bootstrap based confidence envelope based on a normal distribution
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 100, alpha = 0.1, color = "orange", model = "normal") +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
# Bootstrap based confidence envelope based on a normal distribution
ggplot(data = cars, aes(x = speed)) +
stat_density_watercolor(k = 200, alpha = 0.1, color = "orange", model = "normal") +
stat_density(geom = "line") +
theme_bw() +
xlab("Speed") +
ylab("Probability density")
pkgdown::build_article()
pkgdown::build_site()
library(educate)
pkgdown::build_site()
library(educate)
pkgdown::build_site()
pkgdown::build_site()
library(educate)
pkgdown::build_site()
library(educate)
pkgdown::build_site()
?pairwise.table
?stat_density_confidence
?stat_density_confidence
?stat_density_confidence
pkgdown::build_site()
library(educate)
library(educate)
ggplot(data = cars, aes(x = speed)) + stat_density_confidence()
ggplot(data = cars, aes(x = speed)) + stat_density_confidence(model="normal")
ggplot(data = cars, aes(x = speed)) + stat_density_watercolor(k = 100, model="normal")
pkgdown::build_site()
pkgdown::build_site()
set.seed(05882352)
#set random see so you get the same things I do
class1=rnorm(n=100,mean=110,sd=10)
class2=rnorm(n=100,mean=100,sd=10)
class3=rnorm(n=100,mean=90,sd=10)
group=c(rep("1",100),rep("2",100),rep("3",100))
parentincome=rnorm(n=300, mean=100000, sd=20000)
y=c(class1,class2,class3)
#randomly generated data
y1=y+rnorm(n=300,mean=0,sd=10)
y2=0.5*y+rnorm(n=300,mean=50,sd=15)
y3=2*y+rnorm(n=300,mean=-100,sd=20)
y4=0.1*y+rnorm(n=300,mean=90,sd=25)
mydata=data.frame(group,y1,y2,y3,y4, parentincome)
cor(mydata[,2:5])
#factor analysis
f.a=princomp(mydata[,2:5])
plot(f.a)
#scree plot suggests 3 maybe 4 factors.
f.a$loadings
#multivariate regression model
mm=lm(data=mydata, cbind(y1,y2,y3,y4)~group+parentincome,
contrasts=list(group=contr.sum))
#the contrasts bit just lets R know that group is a categorical variable
require(car)
#mancova test
Anova(mm, type="III")
#results suggest 'class' matters, after adjusting.
#now, the question is how?
summary(mm)
install.packages("emmeans")
emmeans::emmeans(mm, specs = group)
emmeans::emmip(mm, specs = group)
emmeans::emmip(mm, ~group)
emmeans::emmeans(mm, ~group)
emmeans::emmeans(mm, ~group + parentincome)
?emmeans::emmeans
emmeans::emmeans(mm, ~group, contrasts=list(group=contr.sum))
man.results = manova(cbind(y1,y2,y3,y4)~group+parentincome, data = mydata)
summary(man.results)
t.pval <- function(y) t.test(y)$p.value
Manova(mm, test.statistic = "Hotelling")
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
games_howell_test(yy ~ group)
??games_howell_test
install.packages("rstatix")
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::games_howell_test(yy ~ group)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::games_howell_test(y ~ group)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::get_emmeans()
?rstatix::get_emmeans
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::get_emmeans(y ~ group + parentincome)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::get_emmeans(formula = y ~ group + parentincome)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::get_emmeans(formula = y ~ group)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::get_emmeans(y ~ group)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::emmeans_test(y ~ group)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::emmeans_test(y ~ group + parentincome)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::emmeans_test(y ~ group)
mydata %>%
tidyr::pivot_longer(
cols = y1:y4,
names_to = 'outcome',
values_to = 'y'
) %>%
group_by(outcome) %>%
rstatix::emmeans_test(y ~ group, covariate = parentincome)
?rstatix
library(educate)
pkgdown::build_site()
devtools::check(document = FALSE, args = c('--as-cran'))
usethis::use_pkgdown()
install.packages(c("BinNonNor", "class", "classInt", "correlation", "corrr", "devtools", "DT", "effectsize", "foreach", "fs", "gdtools", "ggstance", "googlesheets4", "gt", "gtools", "Hmisc", "igraph", "janitor", "lattice", "lme4", "lmerTest", "lubridate", "nlme", "parameters", "pkgdown", "plotly", "quantreg", "RcppArmadillo", "rematch2", "reshape2", "sf", "survival", "tinytex", "usethis", "xaringan", "xfun", "xml2"))
install.packages(c("RcppArmadillo", "sf"))
pkgdown::build_site()
library(educate)
usethis::use_pkgdown()
devtools::check(document = FALSE, args = c('--as-cran'))
library(educate)
library(educate)
library(educate)
usethis::use_pkgdown()
devtools::check_rhub()
devtools::check(document = FALSE, args = c('--as-cran'))
library(educate)
devtools::build_vignettes()
usethis::use_vignette("new")
devtools::check(document = FALSE, args = c('--as-cran'))
devtools::check(document = FALSE, args = c('--as-cran'))
devtools::check(document = FALSE, args = c('--as-cran'))
devtools::check(document = FALSE, args = c('--as-cran'))
library(educate)
devtools::check(document = FALSE, args = c('--as-cran'))
library(educate)
devtools::check(document = FALSE, args = c('--as-cran'))
stringr::str_count("#'    stat_density_watercolor(k = 1000, color = 'skyblue', alpha = 0.03, model = 'none')")
library(educate)
library(educate)
devtools::check(document = FALSE, args = c('--as-cran'))
StatDensityConfidence(data = cars, aes(x = speed))
devtools::check(document = FALSE, args = c('--as-cran'))
devtools::check(document = FALSE, args = c('--as-cran'))
devtools::check(document = FALSE, args = c('--as-cran'))
StatDensityWatercolor(data = cars, aes(x = speed))
library(educate)
ggplot(data = cars, aes(x = speed)) + stat_density_watercolor()
library(ggplot2)
ggplot(data = cars, aes(x = speed)) + stat_density_watercolor()
StatDensityWatercolor()
is.ggproto(StatDensityWatercolor())
is.ggproto(StatDensityWatercolor)
devtools::check(document = FALSE, args = c('--as-cran'))
StatDensityWatercolor
devtools::check(document = FALSE, args = c('--as-cran'))
devtools::check(document = FALSE, args = c('--as-cran'))
